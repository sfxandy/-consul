Safe Restart & Maintenance Process for Consul Servers
Pre-checks

Confirm quorum size

Consul needs a majority of servers to be available to maintain Raft quorum.

Example:

3 servers → quorum = 2

5 servers → quorum = 3

Never take down ≥ (N − quorum + 1) servers at the same time.

Check cluster health

consul operator raft list-peers


All expected peers should show up.

One peer is marked leader.

No peers should be stale.

consul members


All servers should be alive.

Confirm datacenter is consistent.

Rolling maintenance steps (per server)

Do this one server at a time to preserve quorum.

Pick a follower (not the leader)

Prefer restarting a follower first.

Find the leader with:

consul operator raft list-peers


Skip the leader until the end.

Drain traffic from the server (optional but safer)

Mark it ineligible for leader election:

consul operator raft remove-peer <node_id>


or set:

consul operator autopilot promote


Alternatively, use maintenance mode:

consul maint -enable -reason="Server maintenance"


Stop Consul agent cleanly

e.g. systemctl stop consul

Ensure it exits without corruption.

Perform your work

OS patching, Consul upgrade, config changes, etc.

Restart Consul agent

e.g. systemctl start consul

Watch logs (journalctl -u consul -f).

Verify it rejoins cluster

consul operator raft list-peers
consul members


The restarted server should show as a voter again.

Leader should remain unchanged (unless you’re intentionally rotating).

Repeat for other followers

Special case: Restarting the leader

Do this last.

When you stop the leader, the cluster should hold a new election.

Watch logs or run:

consul operator raft list-peers


to confirm a new leader was chosen.

Restart the old leader, verify it rejoins as a follower, then it may later be re-elected.

Post-maintenance validation

Ensure Autopilot is healthy:

consul operator autopilot state


All servers stable, no unhealthy peers.

Check Raft index progression:

consul info | grep raft


commit_index should be moving forward.

Re-enable maintenance if you disabled it.

✅ TL;DR Process

Check quorum → Restart one follower → Verify → Repeat → Restart leader last → Verify cluster healthy.

⚡ Question for you: do you want me to also include a step-by-step upgrade process (i.e. when changing Consul version across the cluster), or just keep this as a restart/maintenance runbook?
